{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "591495296ffbb32c872cf6d9f4e753192c44960f099cc69c22d4eb1ee60cd748"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### GLOBAL CONFIG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "MAKE_NEW_EMBEDDING = True\n",
    "# TODO: RUN_FROM setting (then you can use run-all instead of one by one cell)"
   ]
  },
  {
   "source": [
    "### Preprocess data\n",
    "(only needs to be done once)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre import preprocess\n",
    "# stores preprocessed data file\n",
    "preprocess(i='./data/training.1600000.processed.noemoticon.csv', o='./data/preprocessed.csv', slice=None)"
   ]
  },
  {
   "source": [
    "### Load preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import load_data\n",
    "\n",
    "df = load_data('./data/preprocessed.csv')\n",
    "# TODO: train/dev/test split"
   ]
  },
  {
   "source": [
    "### Embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from emb import get_keras_embedding_layer\n",
    "\n",
    "\n",
    "if MAKE_NEW_EMBEDDING:\n",
    "    MAX_WORDS = 5000\n",
    "    tknzr = Tokenizer(num_words=MAX_WORDS, lower=True, split=' ', oov_token=\"UNK\")\n",
    "    emb_layer = get_keras_embedding_layer(tknzr)\n",
    "\n",
    "    # save emb_layer\n",
    "    with open('models/emb_layer.pkl', 'wb') as output:\n",
    "        pickle.dump(emb_layer, output, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('models/emb_layer.pkl', 'wb') as input:\n",
    "        emb_layer = pickle.load(input)"
   ]
  },
  {
   "source": [
    "### Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model_keras\n",
    "import pickle\n",
    "\n",
    "\n",
    "# TODO: check correct arg-assignment for tknzr\n",
    "model = build_model_keras(tknzr)"
   ]
  },
  {
   "source": [
    "### Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_dev, Y_dev), batch_size=128, epochs=75, verbose=1)\n",
    "\n",
    "if SAVE_TRAINED_MODEL:\n",
    "    with open('models/model.pkl', 'wb') as output:\n",
    "        pickle.dump(model, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "### Evaluate dev"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Save model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Evaluate production (forbidden during tuning)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Explain prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}